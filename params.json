{
  "name": "RBFN learnable",
  "tagline": "RBFN with learnable RBF parameters",
  "body": "## RBFN with learnable RBF parameters\r\nThis post implements a Radial Basis Function Network. We employ the code to classify the MNIST handwritten digits. The parameters of the Gaussian RBF are learnable parameters. Note, an [earlier implementation](http://robromijnders.github.io/RBFN_two_MNIST/), does a RBFN in Matlab, where the centroids and variances of the RBF are fixed.\r\n\r\n# Learnable parameters\r\nThe previous implementation fixes the centroids. The location and spread of the centroids isn't always as obvious like as for the MNIST dataset. The centroids are initialized with a uniform distribution. The variances are randomly initialized around 225. We found that 225 works fine for the MNIST dataset. The common heuristic of setting the standard deviation to the data density didn't make good performance.\r\n\r\n#Results\r\nIf you are working with the code, you can expect these kind of outputs:\r\nThe evolution of accuracy and cross-entropy loss\r\n![loss_evolution](https://github.com/RobRomijnders/rbfn_learnable/blob/master/loss_evolution.png?raw=true)\r\n![loss_accuracy](https://github.com/RobRomijnders/rbfn_learnable/blob/master/acc_evolution.png?raw=true)\r\nThe Tensorboard representation of the computational graph\r\n![graph](https://github.com/RobRomijnders/rbfn_learnable/blob/master/Selection_127.png?raw=true)\r\nThe histograms of the parameters and its gradients\r\n![histograms](https://github.com/RobRomijnders/rbfn_learnable/blob/master/Selection_126.png?raw=true)\r\n\r\n#Improvements\r\n  * The distribution of the centroids exceed [0,1]. In the histograms above we observe that the centroids have values ranging from -3 to +3. An improvement would be to explore the distribution of these points in the dataspace. In necessary, we might clip the entries to [0,1]\r\n  * A visualization of the centroids in the dataspace might learn us a lot on the nature of the RBF layer. The RBF layer has behavior like K-means, where the centroids represent clusters of datapoints. A low dimensional visualization, like t-SNE, will yield valuable insights on this behavior.\r\n  * The implementation of row distances allows for some speed-up. On [this page](https://github.com/tensorflow/tensorflow/issues/2192#issuecomment-216310925) I received some comments from the Tensorflow developers on the issue.\r\n\r\nAs always, I am curious to any comments and questions. Reach me at romijndersrob@gmail.com",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}